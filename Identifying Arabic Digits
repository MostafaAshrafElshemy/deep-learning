# -*- coding: utf-8 -*-
"""Identifying Arabic Digits.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HwDdFhwRdSDSr4LpXD9PHooyA0i12dzZ
"""



"""## Import all the necessary libraries"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import Model
from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten
from tensorflow.keras.optimizers import Adam
from tensorflow.keras import Sequential
from tensorflow.keras.callbacks import EarlyStopping
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import os
import pandas as pd
from sklearn.preprocessing import LabelBinarizer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import confusion_matrix
#from sklearn.metrics import plot_confusion_matrix

"""#Unzip the Dataset"""

!wget 'https://cainvas-static.s3.amazonaws.com/media/user_data/cainvas-admin/arabic.zip'

!unzip -qo arabic.zip
!rm arabic.zip

"""#Load Training and Testing Labels"""

train=pd.read_csv('csvTrainImages 13440x1024.csv')
test=pd.read_csv('csvTestImages 3360x1024.csv')
train_label=pd.read_csv('csvTrainLabel 13440x1.csv')
test_label=pd.read_csv('csvTestLabel 3360x1.csv')

train.head()

"""#Display the Shapes of Training and Testing Labels"""

print("Training Images Shape = ", train.shape)
print("Testing Images Shape = ",test.shape)
print("Training Labels Shape = ",train_label.shape)
print("Testing Labels Shape = ",test_label.shape)

labels = train_label.iloc[:,0].unique()
print(labels)

# Digits vary from 1 - 28

"""#Encoding the labels using Label Binarizer"""

train=np.array(train)
test=np.array(test)
train_label=np.array(train_label)
test_label=np.array(test_label)

X = train
y0 = train_label
binencoder = LabelBinarizer()
y = binencoder.fit_transform(y0)
X_images = X.reshape(-1,32,32)
test_images = test.reshape(-1,32,32)
print(X_images.shape)
print(test_images.shape)

# Split the dataset into training and testing labels
X_train, X_test, y_train, y_test = train_test_split(X_images, y, test_size = 0.2, random_state=90)

"""#Function to Visualize Some Images"""

def visualize_images(df, img_size, number_of_images, name):
    plt.figure(figsize=(8,8))

    n_rows = df.shape[0]
    f = plt.figure(figsize=(15,15)) # defining a figure
    reshaped_df = df.reshape(df.shape[0], img_size, img_size)
    number_of_rows = number_of_images/5 if number_of_images%5 == 0 else (number_of_images/5) +1
    for i in range(number_of_images):
        f.add_subplot(number_of_rows, 5, i+1, xticks=[], yticks=[])
        #plt.figure(figsize = (7,7))
        plt.title(np.argmax(name[i]), color = 'blue', fontdict = {'size' : '25'})
        plt.imshow(reshaped_df[i], cmap='gray')

#visualize_images(X_train,32,20, y_train)

"""#Visualize pixels of one Image"""

def visualize_input(img, ax):
    img = img.reshape(32, 32)
    ax.imshow(img, cmap='gray')
    width, height = img.shape
    thresh = img.max()/2.5
    for x in range(width):
        for y in range(height):
            ax.annotate(str(round(img[x][y],2)), xy=(y,x),
                        horizontalalignment='center',
                        verticalalignment='center',
                        color='white' if img[x][y]<thresh else 'black')

fig = plt.figure(figsize = (15,15))
ax = fig.add_subplot(111, xticks=[], yticks=[])


visualize_input(X_train[0], ax)

# Scaling and shaping the images
X_train = X_train/255
X_test = X_test/255

X_train = X_train.reshape(-1,32,32,1).astype('float32')
X_test = X_test.reshape(-1,32,32,1).astype('float32')

"""#Model Architecture"""

# Defiining Early Stopping function to monitor Validation Loss
es = EarlyStopping(monitor='val_loss', patience=5)

# Defining Model Architecture
model = Sequential()

model.add(Conv2D(32,(3,3),input_shape=(32,32,1),activation='relu'))
model.add(MaxPooling2D(pool_size=(2,2)))

model.add(Conv2D(32,(3,3),activation='relu'))
model.add(MaxPooling2D(pool_size=(2,2)))

model.add(Conv2D(32,(3,3),activation='relu'))
model.add(MaxPooling2D(pool_size=(2,2)))

model.add(Dropout(0.2))
model.add(Flatten())

model.add(Dense(36,activation='relu'))
model.add(Dense(36, activation='relu'))
model.add(Dropout(0.2))
model.add(Dense(28, activation='sigmoid'))
model.summary()

# Compile the model
model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])

"""#Model Training"""

# Run the model for a batch size of 50 for 100 epochs
history = model.fit(X_train,
                    y_train,
                    validation_data = (X_test, y_test),
                    batch_size = 50,
                    epochs = 100,
                    callbacks = [es]
                   )

# Function to plot "accuracy vs epoch" graphs and "loss vs epoch" graphs for training and validation data
def plot_metrics(model_name, metric = 'accuracy'):
    if metric == 'loss':
        plt.title("Loss Values")
        plt.plot(model_name.history['loss'], label = 'train')
        plt.plot(model_name.history['val_loss'], label = 'test')
        plt.legend()
        plt.show()
    else:
        plt.title("Accuracy Values")
        plt.plot(model_name.history['accuracy'], label='train')
        plt.plot(model_name.history['val_accuracy'], label='test')
        plt.legend()
        plt.show()

plot_metrics(history, 'accuracy')
plot_metrics(history, 'loss')

# Saving our trained model
from tensorflow.keras.models import save_model
if os.path.isfile('best_model.h5') is False:
    model.save('best_model.h5')

"""#Evaluating Model Performance"""

#Plotting a confusion matrix for checking the performance of our model
Y_pred = np.argmax(model.predict(X_test), axis = 1)
cnf = confusion_matrix(y_test.argmax(axis = 1), Y_pred)


df_cnf = pd.DataFrame(cnf, range(28), range(28))
sns.set(font_scale = 2)
plt.figure(figsize = (25, 20))
sns.heatmap(df_cnf, annot = True, linewidths = 0.8, fmt = '0.3g', cbar = False)
plt.title("Confusion Matrix")
plt.xlabel("True Values")
plt.ylabel("Prediction Values")
plt.show()

"""#Making Predictions on One Label"""

pred = np.argmax(model.predict(np.expand_dims(X_test[7], axis = 0)))
preds = "Prediction: " + str(pred)
plt.figure(figsize = (7,7))
actual_label = np.argmax(y_test[7]) + 1
plt.imshow(X_test[7])

plt.grid(False)
plt.axis("off")
plt.title(preds)
plt.suptitle("Actual Label " + str(actual_label))

# Saving our trained model
from tensorflow.keras.models import save_model
if os.path.isfile('best_model.h5') is False:
    model.save('best_model.h5')

from tensorflow.keras import models
model = models.load_model('best_model.h5')

!deepCC best_model.h5
